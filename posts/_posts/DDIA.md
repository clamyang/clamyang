---
title: DDIA 读书笔记
comments: true
---

Designing Data-intensive Applications

<!--more-->

## CH1： Reliable, Scalable, Maintainable

主要解释这三个词是什么意思，以及从哪些角度进行思考。



**影响设计数据系统的多个因素**

- 遗留系统的依赖问题
- 设计这个系统的人的经验和技能
- 要交付的时间
- 对风险的容忍度
- 监管限制？ 这个没搞懂，是权限的意思么？



在 DDIA 中主要关注三个方面

- Reliability 可靠性

  即使遇到硬件或软件的 fault，人为的 error 系统应该正常工作。

- Scalability 可扩展性

​		随着系统的增长（规模上），能够妥善的处理增长带来的问题。

- Maintainablity 可维护性

  人员变动随着时间变化着，不同的人维护着同一套代码。



**Reliablity**

- 应用程序像用户期待的那样执行函数
- 可以容忍用户错误的操作或非常规的操作
- 性能可以满足日常需求，并且足以应对突发的负载
- 能够阻止未授权的请求

作者给我们总结了，如果上述的这些条件都满足了，意味着正常工作，我们可以粗略的认为可靠性就是，在系统出错的时候，仍然能正常工作。



这里对错误和失败又进行了区分，有哪些是可以容忍的，哪些是不行的。



错误通常被定义为系统中的一个组件偏离了最初的规范。比如一个接口本应该返回A，但是返回B了。失败通常表示整个系统宕机了，不能正常提供服务。



硬件错误

- 硬盘故障，RAM 故障，电源被关闭了，插错网口了

软件错误

- 软件失控了，把所有计算资源都消耗了。
- Linux 内核错误，导致程序都 hang 住了。
- 系统依赖的服务挂掉了，变成无响应的或者返回错误的响应。
- Cascading failures 这种不知道中文怎么翻译，不过大概意思就是扇面的那种，一个错误导致多个，多个错误导致更多的错误。

​	没有快捷的方法来解决这些系统性的错误在软件中，只能做好监控，识别差异（未能达到预期）

人为错误

- 在某种程度上，最小化系统犯错的机会。
- 在出错最多的地方与引起错误的地方进行解耦。使用与生产环境一样的配置，来探索发现问题。
- 详细的测试工作，单元测试，系统测试，手动测试，自动测试等。
- 能够从人为制造的错误中快速进行恢复，最小化其带来的影响。比如，具备快速回滚的能力
- 配置好详细清晰的监控，比如性能监控和错误比率。当出错的时候，监控数据以及日志对于我们排查问题来说是无价的。
- 对员工有一个完整，良好的培训过程。

总而言之，可靠性会关乎到公司，部门的信誉，和用户的体验也有很大联系。



**可扩展性**

可扩展性是用来描述系统在面对突发负载的能力。当讨论扩展性的使用，其实就是在考虑如下的两个问题：

- 如果系统以某种特别的方式进行增长，我们可以采取什么措施来应对？
- 我们应该怎么增加计算资源来处理额外的负载？



*负载*

负载可以用一些参数来表述：数据库的读写比，同一时间在线的用户数量，缓存的命中率..

作者以 Twitter 为例，具体描述了*负载*。



*性能*

在网络应用中，性能更多的意味着响应时间。

是什么导致了每次响应时间都不相同？

- 后台进程的上下文切换
- 网络丢包，TCP 重传
- GC pause
- 页缺失导致从磁盘重新加载
- 等等



**可维护性**

广为人知的是，软件中的主要开销是维护工作，而不是起初开发。比如，修 Bug，保证系统运行，调研失败原因，适应新的平台，偿还技术债务，添加新的特性等。

三个软件涉及原则：

- 可操作性，Operability

  能使运维团队很容易操作。

- 简易性，Simplicity

  能让新的工程师很容易明白，尽量设计的简洁。

- 可进行性，Evolvability

  能让工程师在修改的时候很方便，可以应对未被考虑到的需求变化，也可以用这几个词来形容，*extensibility*, *modifiability*, or *plasticity*.

（上述的名词翻译都是我自己凭感觉搞得，不存在普遍性）



作者简述了一个好的运维团队应该要做的事情..



## CH2：Data Models And Query Languages

数据模型是按照每一层进行分布的，关键的问题在于每一层是如何表示的？

- 实际生活中，有组织，商品，现金流，传感器，等。我们以对象或者数据结构的方式对其进行建模。可以理解为数据表达方式
- 这些数据是以哪种结构进行存储的，JSON\XML\数据库中的表结构，等等。
- 这些数据是存储在哪种物理器件上的，内存，磁盘，网络中。
- 在更底层，这些内容以电子，脉冲信号的形式存在。



万变不离其宗，每一层都是对底层的封装，提供更简洁接口。



**NoSQL 数据库的诞生**

采纳 NoSQL 数据库的几个驱动力：

- 需要比关系数据库更容易实现的可扩展性，包括非常大的数据集或非常高的写入吞吐量
- 免费开源的软件
- 关系型数据模型并不支持的查询
- 对关系模式的不看好，渴望一个更加动态和富有表达力的数据模型



**Many-to-One and Many-to-Many**

作者在这里探讨了一个点，在多对一或多对多的关系中，为什么存储另一个字段的 ID，二不是值。



举个例子，用户对应的地区，职业，一个用户可以对应到多个地区，工作，家庭住址等，也可以对应到多个职业。



所以，在存储用户对应的这些信息的时候，如果说在页面上需要用户自己输入，那存储用户的具体信息是有意义的。如果在页面上呈现出来的是一个标准的下拉列表，让用户去选择，有很多的好处：

- 一致的格式和拼写
- 避免歧义，比如重名问题
- 利于更新 -- 因为名称仅存在了一个地方，其他都是对它 ID 的引用
- 本地化支持 -- 作者想表达的是国际化时候很方便
- 利于搜索



**网络模型**（The network model）

太复杂不够灵活。



**关系模型**

即使索引改变了，也不需要我们在代码中手动调整指定，查询优化器会自定的帮我们做这些事情。



**文档模型与关系模型**

有利于文档模型的一点就是灵活性，更好的局部性（可以理解为相关的信息都在一起），关系模型中支持连表查询，多对一，多对多的关系。



文档模型中的限制：

- 不能直接引用文档中嵌套的数据，取而代之的是需要说明那个引用在文档中的路径。作者提到只要嵌套不是很深，都不是问题。
- 对 Join 这类查询，无法提供良好的支持，但主要取决于应用。作者提到，比如在用于分析的应用中，可能永远用不到多对多的关系，这时采用文档数据库来存储更合适，比如什么时间发生了什么时间。



文档模型的灵活性

有一点被误解的是，文档数据库是*无模式的*。但是，当代码从数据库中读取数据的时候，通常会假设某种结构用于接收读到的数据，这种模式是隐式的，也不是由数据库强迫加上的。



对于上述情况，有一个更专业的术语 *schema-on-read* ， 还有一种 *schema-on-write* 在写入数据库的时候就已经明确了

*schema-on-read* 像动态类型语言（python），*schema-on-write* 像强类型的语言。



这两种模型的区别在应用想要修改数据格式的时候非常明显：

作者通过修改名称举例，目前采用一个字段进行存储名称，但是现在想通过 *first name* 和 *last name* 的模式进行存储。

文档模型

- 直接在代码中做处理即可

关系模型

- 需要在数据库中添加列
- 然后更新那一列的值

> 在数据库中添加列的操作会使数据库停机，大多数数据库执行 Alter 语句通常在几毫秒内就可以完成，但是 MySQL 中会复制整张表，当处理一张拥有很多数据的表时，这可能会执行几分钟甚至几小时



什么时候使用文档模型最合适？作者给出了两点参考

- 一个对象有很多种类型，把每种类型的对象放在单独的表中不切合实际。
- 外部系统决定数据结构，可能随时改变。



数据库未来的发展：作者提到的是数据库会结合这两者的优点，让应用从中受益。



**图状数据模型**

关系模型的数据库虽然支持多对多的关系，如果应用中存在大量的多对多映射，应考虑使用图来建模。



图由两种对象组成： 顶点（也称为结点或实体）和边（也称为关系或弧）。 很多数据

可以建模为图。 典型的例子包括：

- 社交网络

  顶点是人，边表示哪些人相互认识

- 网络图

- 公路或铁路网

  顶点是交叉路口，边表示公路或铁路



*属性图* 的几个重要方面

- 一个顶点可以通过任意一边连接到其他顶点。没有模式限制哪个类型可以连接哪个类型或者不可以连接。
- 给定一个顶点，可以很高效的找出进来的边，和出去的边。因此可以遍历整张图。
- 使用不同的标签代表不同的关系，可以存储各种各样的信息在一张图中，并且可以维护一个整洁的数据模型。



> 选择性跳过一些内容，不是很感兴趣.. 主要是关于图的查询，比如在关系型数据库中如何使用 SQL 等，还介绍了其他几种不同的图查询语言。



**总结**

这一节主要学到了，document，graph，relational，三种数据模型，

- document 的使用场景主要是，各个数据之间都是独立，一条数据不存在（几乎不）与另一条的关联关系。
- graph 与 document 相反，在图模型中，任何事物都有可能与其他事物关联到一起。

- relational 关系模型是我们接触最频繁的..



突然想到一个问题，要设计某些东西的时候，我们好像没有去发散的思考，这个场景下，是否真的适合使用 MySQL，取而代之的是，为了往 MySQL 上套，强行这样思考。



确实这是一个值得深思的问题，研究问题要从问题的本质出发，而不要被工具束缚。



## CH3：Store and Retrieval

通过标题来看应该是讲，数据的存储和检索。



*作为一个应用开发者，为什么需要关心数据库是如何存储和检索数据的？*

- 虽然我们不需要从头开始实现一个数据库，但是我们需要知道如何进行选择一种最适合我们的



作者通过一个文件进行举例，文件中的每一行都是一个 k-v 形式的键值对。当前这种情况也会遇到很多问题，比如控制并发写入，怎样进行错误处理等..

另外，性能也存在一定的问题，想要寻找某个 Key 对应的 Value 时，只能从头到尾进行遍历，作者由此引出**索引**



不同类型索引之间的共同点：

- 都需要额外增加元数据信息来提高搜索速度



索引的添加和删除并不会影响数据本身的内容，只会影响查询数据的性能。



**Hash Indexes**

作者最开始还是通过文件进行举例，文件还是存储在磁盘上，然后在内存中存储一个 *Hash Map* ， Map 中存储了 key value 是 真正的 val 在 磁盘中的位置。

![](https://s2.loli.net/2022/06/23/sHOQul1pcin5vVW.png)为了防止 log 文件过大的解决办法：

- 设定某一个阈值，当 log 文件达到这个值的时候，就把他拆分成几份。
- 后续的写操作都在另一个新的文件中进行写入。
- 压缩 log 文件，只保留对 key 的最新一次更新，如下。

![](https://s2.loli.net/2022/06/23/vlzUqd79fyIbaRo.png)

- 通过压缩后，可能会导致某一段的文件过小，这里也可以进行段的合并操作，如下。

![](https://s2.loli.net/2022/06/23/Fryci6t4GCm7JIK.png)



正如之前看到的，所有对 log 文件的操作都基于 append 的，为什么不能直接更新之前的操作呢？使用 append-only 的好处是：

- append 的操作是顺序写，而不是随机写，速度快
- 如果 log 文件是 append-only 的，并发和崩溃恢复很容易实现
- 合并之前被拆分的 log 文件，有助于防止 log 文件的碎片化



*Hash Map* 带来的限制：

- hash map 不能太大，必须保证内存可以装下
- 范围查询效率不高



**SSTable and LSM-Trees**

SSTable (Sorted String Table) 按照 Key 进行排序，如下。

![](https://s2.loli.net/2022/06/23/sJRpG2EBAkNMuqC.png)

看的过程中我想到一个问题，不同的 key 在不同的 log 文件中都有存在，是怎么在合并后的 log 文件中进行存储的呢？难道是每次读取到同样的 key 的时候都要再进行一次更新操作吗？



紧接着，作者在下文中就提到了这个问题：

`What if the same key appears in several input segments?`

在看“答案”的时候，作者提到了一点，当出现这种情况的时候，以最新的 log 文件中的数据为准，忽略旧的（在这之前操作）log 文件。



作者简述了一个采用 SSTable 和平衡树（红黑，AVL）作为底层数据结构的存储引擎，工作流程大致如下：

- 当有写操作时，将写操作的内容加入到内存中的平衡树，这种结构也被称为 `memtable`
- 当 `memtable` 超过某个阈值的时候，将其以 SSTable 的形式写入到磁盘中。如果这个时候有新的写操作，可以在一个新的 memtable 中进行插入。
- 当有读操作的时候，会从 memtable 中进行查找，然后在最近的 SSTable 中进行查找，直至找到最后一个
- 后台程序会将 log 文件进行合并、压缩操作。



上述存储引擎存在一个问题，内存作为易失型存储，所以存在 memtable 中的数据是有可能丢失，为了解决这类问题，作者随后提到

- 用一个存储在 disk 中的 log 文件用来存储操作日志，比如写操作发生时，不仅仅在 memtable 中进行插入，也在 log 文件中插入

> 该 log 文件是无序的，因为它只有在宕机等情况发生时才会用到，如果与之对应的 memtable 写入disk后，这个 log 文件也就变成无用的，可以删除掉。



*LSM-tree*

LSM - log structured merge

当在 LSM-tree 中查找一个不存在的 key 时，需要从 memtable 找到最后一个 log 文件。为了优化这个问题，引入了 `Bloom Filter`。

LSM-tree 两种压缩策略

- size-tiered
- leveled



> 以后有兴趣可以深入了解一下，这种存储的数据的策略，这里只是根据书中内容作为简要了解即可！



*B 树*

学过很多次，看看作者是怎么结合实例进行讲解的。。

LSM 最后将数据划分到大小不一的 log 文件中（通常是 Mb）**B** 树采用的是，固定的块大小或页大小（通常大小为 4 KB）的方式进行存储。这样能更贴合硬件，因为磁盘也是采用这种固定大小块的方式进行数据的写入和存储。



B 树中，每一页都是存储在磁盘上，可以通过地址进行索引，并且页与页之间可以相互引用

分支因子：branch childs ，表示一个父节点拥有多少个子节点，实际使用中，分支因子的数量*取决于*存储页引用需要的空间大小和范围边界，通常来说是几百个。



在添加数据到叶子结点的时候，可能会导致页的拆分

![](https://s2.loli.net/2022/06/23/nHFL8C3cNpUty5P.png)

假设当前page已经不能再容纳新的key时，在添加 key 334 后，进行了 page 的拆分。

平衡二叉树通过自旋算法，能想起来的有 LL，RR，LR，RL...保证了任意两个节点之间的只能有一个节点。我记得是有这么一条定义。。记不清楚了。。



作者举例，当 page = 4 KB，branching factor = 500 的时候，一个四层的 B 树可以容纳 250 TB 的数据。



如果在写入数据的时候，数据库崩溃了，会出现什么问题？

- 比如，上述发生插入操作的时候，导致了 page 的分裂，这时候需要将当前这个 range 拆分成两个，并修改父节点对他们的引用。如果这时候数据库崩溃了，可能会出现类似*悬垂指针*的问题。为了解决这个问题，让数据库对崩溃有一定的容错能力，在实现 B-tree 的时候会额外在磁盘上添加一个数据结构，*write-ahead logging* (WAL, 也被称为 redo log)。



> 怪不得都说 DDIA 是必读书籍，读起来就是两个字，畅快。循序渐进，对我这种菜鸟来说太棒了！



WAL ，append-only 的文件格式。**在将修改操作实际应用到磁盘中数据的之前，必须将修改写入到这个文件中**，恢复后，可以使用这个文件进行恢复。



**优化 B 树**

- copy-on-write
- 尽量减少key所占用的空间，可以通过缩写的方式，key 只是用来表明边界的。
- 保持相邻的key在磁盘上的位置也是相邻的，如果一个查询要查出一个很大范文的内容并要求是有序的，一页一页查找的效率十分低下。
  - 想法时候，但是随着数据的增长，很难维护一个这样的数据结构
- 添加额外的指针，将兄弟节点连接起来，这样在遍历的时候就不需要回到父节点找到其他的兄弟节点。
- 从 B 树优化出来一个叫 `fractal tree` 听都没听过...



**对比 B 树 和 LSM 树**

当我们评测存储引擎性能的时候有哪些事情是值得考虑的？

- *write amplification*（写放大）
  - 在数据库的生命周期中，一次写入数据库的操作导致多次写入磁盘的操作被称为写放大。
  - 注：SSD 被写入的次数是有限制的



LSM 优缺点：

```go
// TODO 
```



**索引**

- Secondary Index （二级索引）
  - 索引中 value 存储的是引用
- Clustered Index （聚簇索引）
  - 索引中 value 存储的是数据
- Covring Index （覆盖索引）
  - 是聚簇和非聚簇索引的一种折中方式
  - 覆盖索引对应的 value 中可以包含多个列



注：MySQL 中，二级索引的 value 存储的是主键 id



**多列索引**

作者给我们做了一个科普吧算是，介绍了一维索引的局限性，已经多维索引可以在哪些场景中用到。



**全文搜索，模糊索引**

同上



**事务处理与分析处理**

作者对事务（transaction）进行了解释，并没有像教科书那种直接给出定义，而是结合历史告诉我们，事务一词的来源。以前在商业数据处理中， 一个往数据库中写入的操作往往意味着背后发生了一笔交易，或者是一笔订单，给员工汇款等操作。随着数据库不仅仅用于商业领域，transaction 这个词仍然延续使用。

其代表的是，一个逻辑单元中全部的写操作和读操作。

> 事务并不一定要有 ACID （atomicity, consistency, isolation, durability）



OLTP (online transaction processing)

OLAP (online analystic processing)

![](https://s2.loli.net/2022/06/23/HfGSdbgCRA8rwsX.png)



*数据仓库的由来*

90 年左右，一些公司开始停止在 OLTP 中进行数据分析，而是在一个单独的数据库中进行分析，这种独立的数据库被称为：data warehouse. 数据仓库。



**数据仓库**

从 OLTP 提取数据到  OLAP 的过程被称为： ETL (extract-transform-load)

![image-20220127205128006](https://gitee.com/yangbaoqiang/images/raw/master/blogpics/image-20220127205128006.png)



> 作者提到。。小规模的公司可能都没听过数据仓库。。。身在其中啊。。



**Stars schema and Snowflakes**

这一小节通读下来，可以学习到的是：

星模式-一个主表中存储的都是其他表（子表）的主键。比如，订单表中存储的商户id，商户表中存储了商户信息

雪花模式-星模式的一种变种，子表中存储的其他表的主键。订单表中存储的商户id，商户表中存储了商户信息，还存储了户主信息，户主表中存储了户主的信息。



可以理解为雪花模式是比星模式表达的更完整，拓展的更多的一种模式。



**面向列的存储**

row-oriented 和 column-oriented 存储方式上的区别

![](https://s2.loli.net/2022/06/23/SYNihRLcZBml1gs.png)



*采用位图压缩列*

![image-20220128102336567](https://gitee.com/yangbaoqiang/images/raw/master/blogpics/image-20220128102336567.png)

这里感觉书中描述的不是那么清晰（也可能是我自己翻译后理解的比较烂哈哈）：

- 比如我们有 n 个列，但是经过去重后发现只有 m 个商品，可以通过，建立 m 个 bitmap 然后，每一个 bitmap 的长度是  n 的方式，来压缩列。
- 如果 bitmap 中，对应比特位为 1 说明该行有这个值，为 0，说明无。



*在 bitmap 中查找数据*

![](https://s2.loli.net/2022/06/23/BaonQTIzSVNw9WU.png)

这个地方确实是非常巧妙，比如要找 product_sk 的 id 在 30，68，69 这三个数之间的，直接把这三个对应的 bitmap 找出来，进行 OR 运算，bit 位 是 1 的就代表找到了。



第二个例子中展示了当进行 AND （与）运算的时候，直接将不同的 bitmap 进行 AND，可以这样做的根本原因是，虽然不同的数据在不同的 bitmap 中，但是 bitmap 中的每一位都是彼此对应的。



*内存带宽和矢量化处理*

内存带宽这里涉及到 SIMD 一个指令，包含多个数据。跟普通的三、四地址的指令好像还不太一样。。

 

*data cube and materialized view*

![](https://s2.loli.net/2022/06/23/3E5U7zJTOHlusQS.png)

缓存聚合数据。



## CH4： Encoding and Evolution

Backward compatibility

​	Newer code can read data that was written by older code.

Forward compatibility

​	Older code can read data that was written by newer code.



**数据的编码方式**

程序处理的数据通常由两种（至少）表示方式：

- In memory
- self-contained sequence of bytes （Json）



encoding ： In memory ---> sequence



*二进制编码*

Facebook - Thirft 

- Thrift 有两种压缩方式： *BinaryProtocol* and *CompactProtocol*

Google - Protobuf

- Protobuf 只有一种压缩方式，从书中结论来看，比 Thrift 压缩的要小一点，但是差别不大。

Thrift 采用如下第一种的方式声明 schema

![](https://s2.loli.net/2022/06/23/5DMGen3OPgULca9.png)



Thrift - BinaryProtocol

![](https://s2.loli.net/2022/06/23/Xj38cVD1rpgG67z.png)

有数据类型标识，字段的 tag （表示字段名称），可以在图中看到有很多地方都是 00 ，这些未用到字节，如果可以进一步被压缩，仍然可以节省很多空间。

由此可以引出 Thrift 的第二种压缩方式：CompactProtocol ，它确实也是这么做的，通过把更多的信息**pack到尽可能少的字节中**，这是不是和 SIMD 的基本思想是相同的？从 59 字节压缩到 34 字节，优化了将近 50 %的size。

如下图，把数据类型和字段的tag, pack 到了一个字节。

![](https://s2.loli.net/2022/06/23/TZsguR4KqAoweaD.png)



> 这章节后半部分是在手机上阅读的。。没来得及做笔记整理，等我二刷中文版的时候，着重把这块补上。



## CH5：Replication

从单一的数据系统转变为分布式的数据系统。



分布式系统有两种形式的存在方式

- Replication
- Partitioning

某些情况下，这两种模式会混合使用，下图中展示了，一个数据库分成了两个分片，又为两个分片搞了两个副本。

![](https://s2.loli.net/2022/06/23/AgezPrCvyl1Nd3B.png)



*为什么需要 replication*

- 在距离上离用户更近
- 当某部分出错时可以保证系统正常工作
- 水平扩展机器，增加吞吐量



**Leaders And Followers**

*如何却确保 master 的数据到达了所有的  slave 上？*

![](https://s2.loli.net/2022/06/23/SHL7jerUyf6pMq2.png)



*Synchronous Versus Asynchronous Replication*

![](https://s2.loli.net/2022/06/23/CKQRLSyi1XpAtdU.png)



同步的优缺点

- slaves 一定是最新的副本，与 master 中保持一致

缺点

- 如果同步过程中 slave 没有响应，如上图 Follower 1 的处理时间会变成不可预测的。这时 master 不会处理任何写操作，直到收到 slave 的响应。



异步的缺点：

- 如果 master 崩溃了，可能会导致数据的丢失，即主从节点存储的数据不一致



**配置新的 slave**

当一个 slave 加入到 cluster 中，slave 如何进行数据的同步。

- 打快照
- 将快照发送到 slave
- slave 连接到 master ，同步从 *打快照时间之后* 做的数据变更
- 上一步执行完成后，与其他的 slave 同步数据的方式就没有什么不同了



**处理崩溃节点**

- **catch-up recovery**

- **Failover** 故障转移



**replication logs 的实现**

用于slave同步数据的文件，是怎么存储 master 的操作日志的？

- 基于语句的实现

  - 压缩性好
  - 如果master 中用了 NOW() 这样的函数，这样在 slave 中执行会出问题的
    - 解决办法就是，计算出确定的值然后存储的 log 文件中

- WAL

  这里提到了怎样使用这个技术是实现数据库版本的升级，简而言之，先给 slave 节点进行升级，然后执行故障转移，让已经升级的 slave 成为 master 节点。

  > 这种方式的一个缺点就是，slave 和 存储引擎是紧耦合的

- 基于行 row 的实现

  - MySQL 触发器，逻辑日志

- 基于 trigger 的实现

  就是在执行相应语句时，执行特定的函数



**slave 节点同步数据滞后的问题**

似乎每种高可用都有这类问题，如果在主库修改了一个数据，紧接着读取数据，这时候从节点去服务这个读请求，就会出现数据不一致的问题。



> 第五章，一部分是在手机上读的没来得及做笔记。。二刷一定补上！



## CH6：Partitioning

分布式数据库的另一种存储方式，分片，即每个地方只存储一部分数据，各个分片的内容合并起来才是一个完整的数据。



如何将一个大的数据库进行分片？

如何与分片进行交互，即数据的查询？

如何找到数据所在的正确的分片？



**分片和副本**

这俩通常会结合使用，如下：

![](https://s2.loli.net/2022/06/23/5RDAsTzKv1um27e.png)



#### Key-Value 类型数据的分片

学到了几个名词：

skewed 倾斜，某个分区的数据要多余其他分区，把这种情况称为倾斜。

hot pot 热点，某个分区的负载比其他分区都要高，把这种情况的分区叫做热点。



避免热点分区最简单的方法就是，插入记录的时候随机选择分区。



![](https://s2.loli.net/2022/06/23/WtIMG4HnEqiV9O7.png)

图中索引为 12 的范围，包括了 T - Z，这种简单的将一本书包括两个字母索引，会导致其他的卷包含的索引不均匀。*为了使数据分布的更均匀，分区的边界需要适应数据。*



#### 通过 key 的 hash 值进行分区

![](https://s2.loli.net/2022/06/23/MOtpjgGC39NvHi8.png)



使用key的哈希值作为分区，给我们带来的一个损失就是：没办法执行高效的范围查询。



**Skewed Workloads and Relieving Hot Spots**

倾斜的工作负载指的是，某个分区的负载要明显高于其他分区。比如社交媒体中的明星有很多的粉丝，这种情况下很容易引起，瞬间大量操作同一个 key。



解决这种问题的办法就叫做：Relieving Hot Spots

就是让打在同一个分区上的请求，再次分布到别的分区之中。

作者提到的一个最简单的方法是：在 key 的开头或结尾添加随机数，这两个随机数可以将打在一个分区的请求均匀分布到 100 个 key 上，而不是只操作一个 key。



但是这又带来了另一个问题，就是读取数据的时候变得更加困难，需要将这100个key 都读取出来，再做汇总。

 

#### Partitioning and Secondary Indexes

**Partitioning Secondary Indexes by Document**

主要讲了分区和二级索引怎么搭配使用。

![](https://s2.loli.net/2022/06/23/6ysve8u5AQb3GoZ.png)

基于文档的二级索引分区，每个分区中的二级索引都是独立的，各自维护各自的索引，也被称为本地索引。



**Partitioning Secondary Indexes by Term**

按术语划分二级索引

![](https://s2.loli.net/2022/06/23/1K6k2lfeo5i8jbr.png)

与基于文档的方式相比，很容易看出，二级索引变成了全局索引。



但是也不能把索引全部放在一个分区上，会破坏分区的目的，也可能会成为性能的瓶颈。



#### Rebalancing Partitions

为什么我们需要对分区进行重平衡？

- 查询吞吐量增加，需要添加 CPU 应对高负载。
- 数据规模增长，需要添加磁盘和 RAM 存储。
- 机器宕机的时候，其他的机器需要接管失败的机器。



*rebalancing* 的过程就是，将集群中一个节点负载转移到另一个。



期望 *rebalancing* 达到什么目的？

- 在重平衡之后，负载能够均匀的分布在集群的节点上。
- 即发生了 rebalancing，也可以正常处理读、写请求。
- 不应该在节点间移动不必要的数据，快速重新平衡并最小化网络和磁盘 I/O 负载。



**重平衡的策略**

*hash mod N*

对 N 取模带来的问题是，如果 node 数量 N 变化了，大多数 key 都需要从原 node 移动到另一个 node。



*固定数量的 partitions*

这里采用了一种在 node 上创建比 node 数量更多分区的方法，比如 node 数量是 10，一个 node 上创建 100 个分区，这样总数就是 1000 个分区。



按照上述的分配，如果这是新加入了一个 node ，这个新的 node 从那 10 个 node 上 steal 几个分区过来，如下图。

![](https://s2.loli.net/2022/06/23/2NsHbOV91EWfJ38.png)

分区编号不会改变，分区中的 key 也不会改变。唯一改变的就是分区所在的 node，但是这个改变不是立即发生的，通过网络传输数据到另一个 node 需要花费很多时间。



这时，旧的分区在这个传输的过程中仍然用于处理读写请求。

这种模式在 ES 中有使用到。



一般是怎么确定固定数量的分区的数量呢？

- the number of partitions configured at the outset is the maximum number of nodes you can have



> 管理分区也是有开销的，所以选择了一个非常高的分区数量时，可能会适得其反。



*动态 partitions*

大的会拆成小的，太小了会合并成一个。

动态分区的好处

- 分区的数量可以适应数据的变化。



> 空的数据库会以一个唯一的分区开始，这时所有的读写操作只操作一个分区，直到达到了需要拆分的阈值。



**Partitioning proportinally to nodes**





**自动或手动进行重平衡**

自动会很方便，运维只需要做很少的操作就能达到维护的目的。但是自动重平衡是不可预测的。



当自动重平衡和故障检测结合使用时会更加危险，比如某个 node 负载比较高，会时不时出现响应慢的问题。这时其他节点要是判定这个 node 崩溃了，开启了自动重平衡，这不是我们期待的结果。



所以，手动的可能没有自动的那么方便，但是可以阻止一些额外的问题。



#### 请求路由

常见的三种方式：

- 直接访问一个node 如果有就返回，没有就找下一个node
- 通过路由的方式，在 client 和 node 中间套一层。
- 第三种需要客户端进行配合，客户端对哪些分区存储了哪些key是有感知的。

![](https://s2.loli.net/2022/06/23/FUslPBcKGLAHT2R.png)



另一种方式为，分布式系统以来一个独立的服务，比如 ZooKeeper 来跟踪集群中的元数据。

![](https://s2.loli.net/2022/06/23/WwbyJRN1YHX2eSp.png)





#### 总结

这章讲了几种将数据库拆成分区的方法，不过针对的好像都是 key-value 类型的数据库。



分区的目的：**将数据和查询的负载更均匀的分配到多台机器上**



两种分区的方法：

- key range 的分区方法，将 key 排序后进行存储的一个好处是，支持更高效的范围查询，同时也会带来一种风险，就是 hot spot 的问题。这种分区方式通常结合**动态分区**进行使用，在达到某个阈值的时候进行分区的拆分。
- hash 分区，通过散列函数将数据更均匀的分布在多台机器上。虽然损失了高效的范围查询，但是给我们带来了更均匀的数据分布和负载均衡。hash 分区的方式通常结合**固定数量**的分区进行使用。



*分区和二级索引*的结合

- 基于文档的，也叫 local index
- 基于术语的，也叫 global index



## Ch7：Transactions

循序渐进，介绍了一些会导致数据系统出错的几个问题

- 数据库软件或者硬件可能会随时出错，也包括在写操作执行一般的过程中
- 应用可能会随时崩溃，包括一些逻辑只执行了一半
- 网络的不可靠，切断了应用和数据库之间的关系
- 客户端之间的并发操作
- 客户端可能读取到了无意义的数据（脏数据）



**事务**

事务是简化上述问题的一种机制。**事务是应用程序将多个读取和写入组合成一个逻辑单元的一种方式。**

概念上，所有的读写操作在一个事务中被看成是一个操作，要么整个事务成功（commit），要么全部失败（abort, rollback）。



这下我就有点明白了，总说的分布式事务是什么意思，比如一个写请求，需要多个服务进行协调，为了保证数据的可靠性，要么所有的服务都响应成功，要么就都失败。

#### ACID

atomicity 原子性

consistency 一致性

isolation 隔离性

durability 持久性



是数据库中的容错机制建立精确的术语



**Atomicity**

atomic 这个词通常代表的意思是，一个不可再分的操作。



在计算机中，代表着一些其他的意思，比如多线程环境下，某个线程修改了某个值，由 1 改成 2，这时候其他线程是看不到的，其他线程看到的仍然是 1。



**但是在 ACID 中**，A 代表的意思是和并发没有任何关系的！像上述这种问题，在 ACID 中 I isolation 中覆盖了这样的场景。



Atomicity 描述了如果客户端想要请求多个写操作，但是在一部分写操作执行完成后发生了错误。如果多个写操作聚合到一个 atomic 事务中，就说明这个事务是由于错误未完成的，然后这个事务就可以进行回滚，数据库必须忽略和恢复写入成功的值。



**发生错误时，有回滚事务的能力，并且这个事务中的所有写操作都应该被忽略。**这是 ACID 中 A 的定义。



作者提到 abortability（可回滚能力）可能更适合这个 A。



**Consitency**

ACID中的一致性的主要是指对数据有特定的预期状态， 任何数据更改必须满足这些状态约束（或者恒等条件）。

> 说实话，这句话有点难懂。。原文是这样的 `The idea of ACID consistency is that you have certain statements about your data (invariants) that must always be true`



关于一致性的描述确实很模糊，看完知乎上这个回答清晰了很多。

![](E:/resource/myInfo/blogRes/images-master/blogpics/image-20220218100501876.png)



**通常，应用程序会依赖数据库的 A 和 I 来实现 C**



**Isolation**

![](https://s2.loli.net/2022/06/23/P5oRqwhxXcZWnuT.png)这个就有点和一开始说的 atomic 并发访问类似了。



**Durability**

数据库系统的目的就是提供一个安全的地方，可以用来存放数据，并且不需要担心数据的丢失。



单节点中，持久性意味着数据成功的写入了。master - slave 中，意味着副本中的数据也成功写入了。



完美的持久性其实并不存在，如果存储数据的磁盘和存储副本数据的磁盘都坏了，这也是一种情况。



#### 单对象与多对象事务操作

![](https://s2.loli.net/2022/06/23/2yncBqfrW1Ie6EU.png)

如果没有隔离性，user2 会看到一种非常诡异的现象，就是有未读邮件，但是未读邮件的数量显示为 0。



![](https://s2.loli.net/2022/06/23/BzUa3sCGQqlfXxk.png)

如果没有原子性，这时候未读邮件和未读数量的显示就不一致了。这种情况下，第二个更新数量的操作失败了，那么第一个插入未读邮件的操作是需要回滚的。



**多对象事务的需求**

主要还是为了事务的  A 和 I



**错误处理和驳回**

事务一个非常重要的特点：当错误发生的时候，可以进行驳回（忽略已修改的内容）并且安全的重试。



ACID 的哲学：**如果数据库违背了 AID ，那还不如摒弃 AID，这样也比把数据搞成半截子强。**



重试事务也会有很多问题：

- 比如事务执行成功了，但是 commit 未返回给客户端，此时客户端会认为这个事务是失败的，这样就会导致事务执行多次。。除非有一种去重的机制。。
- 如果事务执行失败是由于过载导致，那么事务的重试会加重负载。这种情况下可以添加重试次数的限制。
- 只有在”可控的“错误发生时，事务重试才有意义。如果这个事务中本身就有错误，那么怎么重试都是无意义的。（这句话是我自己理解的）
- 如果事务的执行存在数据库之外的副作用，那么即使事务被驳回了，副作用仍然会发生。作者举了一个例子，特别好！如果这个事务的执行伴随着发送邮件，那么重试的时候仍然会发送邮件。。



#### 弱隔离级别

##### Read committed

读提交是最基础的事务隔离级别，提供了两种保障：

- 当从数据库读的时候，只能读到已经被 committed 的内容。**No dirty reads**
- 当写操作发生时，只有在事务 committed 的时候，才会覆盖原数据。**No dirty writes**



**No dirty reads**

dirty reads （脏读）如果一个事务对数据库中的内容进行了修改，但是事务还没提交，这时候另一个事务要是读到了未提交的数据，称这种情况未脏读。



读提交的事务隔离级别，**必须阻止脏读**，意味着所有的写操作只有在 committed 后才能被看到，如下图：

![](https://s2.loli.net/2022/06/23/a6pN7lZYxej2O5c.png)



**No dirty writes**

dirty writes （脏写）如果一个未提交的事务修改的内容，被另一个事务覆盖了，这种情况称为脏写。

![](https://s2.loli.net/2022/06/23/8HPdxRcOYFwkts1.png)

#### 实现读提交隔离级别

写 ： 大多数情况，数据库实现读提交隔离级别都是通过**行级别**的锁来实现的，如果某个事务想修改某个值，一定要先获取锁。

读 ： 要是不想脏读，也可以通过行级锁实现，但是可能会出现一个写事务，阻塞非常多的读事务。更普遍的方式是，通过上边的 7-4 图中那样的方法。



#### Snapshot Isolation and Repeatable Read

快照隔离和可重复读。



读提交中存在的问题：

![image-20220221151207197](https://gitee.com/yangbaoqiang/images/raw/master/blogpics/image-20220221151207197.png)

这个账户有 1000 ，分成两个账户，每个中有 500。这个用户账上发生了一笔交易，从一个账户转移到另一个账户 100。



两个事务，一个读的，一个写。她查询第一个账户是 500，但是读提交的事务只有在整个事务 commit 后才能被看到，所以在事务提交后，她再次查账户是 400，但是她本来是 1000 块钱，那 100 就莫名其妙消失了。。



**快照隔离的一个关键原则是：读不会阻塞写，写不会阻塞读**



**MVCC**

数据库必须保存某个对象的多个不同提交版本，因为不同的进行中事务需要在不同时间看到不同的数据库状态。*因为在同一时刻保存了某个对象的多个版本，这个技术被称为 MVCC*



**快照隔离的实现**

当事务开始的时候，会给每个事务一个唯一且自增的事务 ID。

![](https://s2.loli.net/2022/06/23/G2OBu1VwpkaWLNI.png)

如图所示，一个更新操作在内部被拆分成了删除和插入。事务13 要更新账户 1  的余额，把 created by = 3 的删除，插入了一条新的。



**一致性快照的可见性规则**

*事务 ID 决定了他可以看到哪些对象，哪些看不到*

- 在事务开始的时候，数据库会创建一个在那个时刻其他正在执行的但是还没有提交或驳回的事务列表。
- 被驳回事务的写操作会被忽略。
- 事务 ID 更大的写操作会被忽略掉，尽管这些事务被提交了。
- **所有其他写入对应用程序的查询都是可见的。**



在快照隔离中，如果一个对象是可见的，必须满足以下两个条件：

- 在读事务开启的时候，在另一个事务中创建的对象已经 commit 了。
- 对象没有被标记为删除，如果被删除了，当读事务开启的时候，请求删除的事务还没有提交。



**索引在快照隔离中是怎样工作的**

主要是讲了两种建立索引树的方式。

- append-only
  - 有写事务的时候，会从某个特定的根创建一颗新的索引树
- copy-on-write
  - 写时复制，针对当前 page 进行操作的，如果想要更新的话，并不会覆盖当前页的内容，而是创建当前页的一个副本。



**可重复读和命名混乱**

MySQL 中把快照隔离称为**可重复读**



#### 幻读

一个事务中的写操作影响了另一个事务中的查询操作。



